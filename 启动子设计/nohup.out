2023/08/29 10:29:51 INFO mlflow.utils.conda: Conda environment mlflow-b9e54fab5e8bdc2e9dc6b71f2cf644b980a4207b already exists.
2023/08/29 10:29:51 INFO mlflow.projects.utils: === Created directory /tmp/tmpd594pzck for downloading remote URIs passed to arguments of type 'path' ===
2023/08/29 10:29:51 INFO mlflow.projects.backend.local: === Running command 'source /user/sunjinyuan/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-b9e54fab5e8bdc2e9dc6b71f2cf644b980a4207b 1>&2 && python train.py config/train_tss50.py --device=cuda --n_layer=3 --n_head=4 --n_embd=4' in run with ID 'bad21bac4db046a4ad707d3407ad03b5' === 
Traceback (most recent call last):
  File "/user/sunjinyuan/promotor_mlflow/train.py", line 27, in <module>
    from torch.nn.parallel import DistributedDataParallel as DDP
  File "/user/sunjinyuan/miniconda3/envs/mlflow-b9e54fab5e8bdc2e9dc6b71f2cf644b980a4207b/lib/python3.9/site-packages/torch/nn/__init__.py", line 1, in <module>
    from .modules import *  # noqa: F403
  File "/user/sunjinyuan/miniconda3/envs/mlflow-b9e54fab5e8bdc2e9dc6b71f2cf644b980a4207b/lib/python3.9/site-packages/torch/nn/modules/__init__.py", line 1, in <module>
    from .module import Module
  File "/user/sunjinyuan/miniconda3/envs/mlflow-b9e54fab5e8bdc2e9dc6b71f2cf644b980a4207b/lib/python3.9/site-packages/torch/nn/modules/module.py", line 8, in <module>
    from ..parameter import Parameter
  File "/user/sunjinyuan/miniconda3/envs/mlflow-b9e54fab5e8bdc2e9dc6b71f2cf644b980a4207b/lib/python3.9/site-packages/torch/nn/parameter.py", line 2, in <module>
    from torch._C import _disabled_torch_function_impl
ImportError: libtorch_python.so: cannot open shared object file: No such file or directory
2023/08/29 10:29:52 ERROR mlflow.cli: === Run (ID 'bad21bac4db046a4ad707d3407ad03b5') failed ===
2023/08/29 10:35:23 INFO mlflow.utils.conda: === Creating conda environment mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7 ===
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done
Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
Installing pip dependencies: ...working... done
2023/08/29 10:44:01 INFO mlflow.projects.utils: === Created directory /tmp/tmpbaggbht4 for downloading remote URIs passed to arguments of type 'path' ===
2023/08/29 10:44:01 INFO mlflow.projects.backend.local: === Running command 'source /user/sunjinyuan/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7 1>&2 && python train.py config/train_tss50.py --device=cuda --n_layer=3 --n_head=4 --n_embd=4' in run with ID 'b7a15227dc984865ba0d561a9330f0d2' === 
Overriding config with config/train_tss50.py:
# train a miniature character-level shakespeare model
# good for debugging and playing on macbooks and such

out_dir = 'out-tss50'
eval_interval = 250 # keep frequent because we'll overfit
eval_iters = 200
log_interval = 10 # don't print too too often

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

# wandb_log = True # override via command line if you like
# wandb_project = 'tss50'
# wandb_run_name = 'mini-gpt-4-8-512'

dataset = 'tss50'
gradient_accumulation_steps = 1
batch_size = 64
block_size = 256 # context of up to 256 previous characters

# baby GPT model :)
n_layer = 3
n_head = 4
n_embd = 128
dropout = 0.2

learning_rate = 1e-3 # with baby networks can afford to go a bit higher
max_iters = 5000
lr_decay_iters = 5000 # make equal to max_iters usually
min_lr = 1e-4 # learning_rate / 10 usually
beta2 = 0.99 # make a bit bigger because number of tokens per iter is small

warmup_iters = 100 # not super necessary potentially

# on macbook also add
device = 'cuda:0'  # run on cpu only
compile = False # do not torch compile the model

Overriding: device = cuda
Overriding: n_layer = 3
Overriding: n_head = 4
Overriding: n_embd = 4
training config:
tokens per iteration will be: 16,384
found vocab_size = 5 (inside data/tss50/meta.pkl)
Initializing a new model from scratch
number of parameters: 0.00M
num decayed parameter tensors: 14, with 1,620 parameters
num non-decayed parameter tensors: 7, with 28 parameters
using fused AdamW: True
step 0: train loss 1.5997, val loss 1.5994
Traceback (most recent call last):
  File "/user/sunjinyuan/promotor_mlflow/train.py", line 308, in <module>
    logits, loss = model(X, Y)
  File "/user/sunjinyuan/miniconda3/envs/mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/user/sunjinyuan/promotor_mlflow/model.py", line 188, in forward
    x = block(x)
  File "/user/sunjinyuan/miniconda3/envs/mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/user/sunjinyuan/promotor_mlflow/model.py", line 111, in forward
    x = x + self.attn(self.ln_1(x))
  File "/user/sunjinyuan/miniconda3/envs/mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/user/sunjinyuan/promotor_mlflow/model.py", line 72, in forward
    y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 31.75 GiB total capacity; 127.96 MiB already allocated; 30.72 GiB free; 156.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023/08/29 10:44:20 ERROR mlflow.cli: === Run (ID 'b7a15227dc984865ba0d561a9330f0d2') failed ===
2023/08/29 10:47:37 INFO mlflow.utils.conda: Conda environment mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7 already exists.
2023/08/29 10:47:37 INFO mlflow.projects.utils: === Created directory /tmp/tmpa7y6a6k8 for downloading remote URIs passed to arguments of type 'path' ===
2023/08/29 10:47:37 INFO mlflow.projects.backend.local: === Running command 'source /user/sunjinyuan/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7 1>&2 && python train.py config/train_tss50.py --device=cuda --n_layer=3 --n_head=4 --n_embd=4' in run with ID '20ec4874ad784bffa98c8c992d27a6b8' === 
Overriding config with config/train_tss50.py:
# train a miniature character-level shakespeare model
# good for debugging and playing on macbooks and such

out_dir = 'out-tss50'
eval_interval = 250 # keep frequent because we'll overfit
eval_iters = 200
log_interval = 10 # don't print too too often

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

# wandb_log = True # override via command line if you like
# wandb_project = 'tss50'
# wandb_run_name = 'mini-gpt-4-8-512'

dataset = 'tss50'
gradient_accumulation_steps = 1
batch_size = 16
block_size = 256 # context of up to 256 previous characters

# baby GPT model :)
n_layer = 3
n_head = 4
n_embd = 128
dropout = 0.2

learning_rate = 1e-3 # with baby networks can afford to go a bit higher
max_iters = 5000
lr_decay_iters = 5000 # make equal to max_iters usually
min_lr = 1e-4 # learning_rate / 10 usually
beta2 = 0.99 # make a bit bigger because number of tokens per iter is small

warmup_iters = 100 # not super necessary potentially

# on macbook also add
device = 'cuda:0'  # run on cpu only
compile = False # do not torch compile the model

Overriding: device = cuda
Overriding: n_layer = 3
Overriding: n_head = 4
Overriding: n_embd = 4
training config:
tokens per iteration will be: 4,096
found vocab_size = 5 (inside data/tss50/meta.pkl)
Initializing a new model from scratch
number of parameters: 0.00M
num decayed parameter tensors: 14, with 1,620 parameters
num non-decayed parameter tensors: 7, with 28 parameters
using fused AdamW: True
step 0: train loss 1.5996, val loss 1.5993
Traceback (most recent call last):
  File "/user/sunjinyuan/promotor_mlflow/train.py", line 313, in <module>
    scaler.scale(loss).backward()
  File "/user/sunjinyuan/miniconda3/envs/mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/user/sunjinyuan/miniconda3/envs/mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 31.75 GiB total capacity; 83.52 MiB already allocated; 30.77 GiB free; 106.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023/08/29 10:47:46 ERROR mlflow.cli: === Run (ID '20ec4874ad784bffa98c8c992d27a6b8') failed ===
2023/08/29 10:48:15 INFO mlflow.utils.conda: Conda environment mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7 already exists.
2023/08/29 10:48:15 INFO mlflow.projects.utils: === Created directory /tmp/tmpc10b9_ro for downloading remote URIs passed to arguments of type 'path' ===
2023/08/29 10:48:15 INFO mlflow.projects.backend.local: === Running command 'source /user/sunjinyuan/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-4353a5db5c24b60d97dcdd4e9ff7ae0e440ce7f7 1>&2 && python train.py config/train_tss50.py --device=cuda --n_layer=3 --n_head=4 --n_embd=4' in run with ID 'c3aa706c3d5245a18667a1319133a44c' === 
Overriding config with config/train_tss50.py:
# train a miniature character-level shakespeare model
# good for debugging and playing on macbooks and such

out_dir = 'out-tss50'
eval_interval = 250 # keep frequent because we'll overfit
eval_iters = 200
log_interval = 10 # don't print too too often

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

# wandb_log = True # override via command line if you like
# wandb_project = 'tss50'
# wandb_run_name = 'mini-gpt-4-8-512'

dataset = 'tss50'
gradient_accumulation_steps = 1
batch_size = 8
block_size = 256 # context of up to 256 previous characters

# baby GPT model :)
n_layer = 3
n_head = 4
n_embd = 128
dropout = 0.2

learning_rate = 1e-3 # with baby networks can afford to go a bit higher
max_iters = 5000
lr_decay_iters = 5000 # make equal to max_iters usually
min_lr = 1e-4 # learning_rate / 10 usually
beta2 = 0.99 # make a bit bigger because number of tokens per iter is small

warmup_iters = 100 # not super necessary potentially

# on macbook also add
device = 'cuda:0'  # run on cpu only
compile = False # do not torch compile the model

Overriding: device = cuda
Overriding: n_layer = 3
Overriding: n_head = 4
Overriding: n_embd = 4
training config:
tokens per iteration will be: 2,048
found vocab_size = 5 (inside data/tss50/meta.pkl)
Initializing a new model from scratch
number of parameters: 0.00M
num decayed parameter tensors: 14, with 1,620 parameters
num non-decayed parameter tensors: 7, with 28 parameters
using fused AdamW: True
step 0: train loss 1.5997, val loss 1.5994
iter 0: loss 1.6014, time 1688.59ms, mfu -100.00%
iter 10: loss 1.5973, time 6.34ms, mfu 0.00%
iter 20: loss 1.5990, time 6.54ms, mfu 0.00%
iter 30: loss 1.5924, time 6.57ms, mfu 0.00%
iter 40: loss 1.5852, time 6.56ms, mfu 0.00%
iter 50: loss 1.5761, time 6.56ms, mfu 0.00%
iter 60: loss 1.5713, time 6.62ms, mfu 0.00%
iter 70: loss 1.5600, time 6.56ms, mfu 0.00%
iter 80: loss 1.5540, time 6.52ms, mfu 0.00%
iter 90: loss 1.5464, time 6.36ms, mfu 0.00%
iter 100: loss 1.5360, time 6.90ms, mfu 0.00%
iter 110: loss 1.5274, time 8.63ms, mfu 0.00%
iter 120: loss 1.5166, time 9.98ms, mfu 0.00%
iter 130: loss 1.5138, time 10.49ms, mfu 0.00%
iter 140: loss 1.5068, time 10.71ms, mfu 0.00%
iter 150: loss 1.5011, time 11.80ms, mfu 0.00%
iter 160: loss 1.4997, time 6.31ms, mfu 0.00%
iter 170: loss 1.4852, time 6.27ms, mfu 0.00%
iter 180: loss 1.4824, time 6.26ms, mfu 0.00%
iter 190: loss 1.4815, time 6.24ms, mfu 0.00%
iter 200: loss 1.4781, time 6.34ms, mfu 0.00%
iter 210: loss 1.4722, time 6.31ms, mfu 0.00%
iter 220: loss 1.4669, time 6.31ms, mfu 0.00%
iter 230: loss 1.4658, time 6.27ms, mfu 0.00%
iter 240: loss 1.4674, time 6.34ms, mfu 0.00%
step 250: train loss 1.4634, val loss 1.4636
saving checkpoint to out-tss50
iter 250: loss 1.4583, time 1128.49ms, mfu 0.00%
iter 260: loss 1.4619, time 6.27ms, mfu 0.00%
iter 270: loss 1.4634, time 6.27ms, mfu 0.00%
iter 280: loss 1.4569, time 6.43ms, mfu 0.00%
iter 290: loss 1.4505, time 6.54ms, mfu 0.00%
iter 300: loss 1.4534, time 6.30ms, mfu 0.00%
iter 310: loss 1.4657, time 6.25ms, mfu 0.00%
iter 320: loss 1.4548, time 6.41ms, mfu 0.00%
iter 330: loss 1.4563, time 6.47ms, mfu 0.00%
iter 340: loss 1.4509, time 6.40ms, mfu 0.00%
iter 350: loss 1.4551, time 6.26ms, mfu 0.00%
iter 360: loss 1.4484, time 6.57ms, mfu 0.00%
iter 370: loss 1.4557, time 6.41ms, mfu 0.00%
iter 380: loss 1.4463, time 6.32ms, mfu 0.00%
iter 390: loss 1.4544, time 7.00ms, mfu 0.00%
iter 400: loss 1.4450, time 7.79ms, mfu 0.00%
iter 410: loss 1.4547, time 6.44ms, mfu 0.00%
iter 420: loss 1.4497, time 6.32ms, mfu 0.00%
iter 430: loss 1.4495, time 6.70ms, mfu 0.00%
iter 440: loss 1.4456, time 6.69ms, mfu 0.00%
iter 450: loss 1.4518, time 6.54ms, mfu 0.00%
iter 460: loss 1.4521, time 6.63ms, mfu 0.00%
iter 470: loss 1.4503, time 6.54ms, mfu 0.00%
iter 480: loss 1.4570, time 6.64ms, mfu 0.00%
iter 490: loss 1.4378, time 6.59ms, mfu 0.00%
step 500: train loss 1.4489, val loss 1.4498
saving checkpoint to out-tss50
iter 500: loss 1.4517, time 1002.87ms, mfu 0.00%
iter 510: loss 1.4532, time 6.25ms, mfu 0.00%
iter 520: loss 1.4545, time 6.26ms, mfu 0.00%
iter 530: loss 1.4420, time 6.58ms, mfu 0.00%
iter 540: loss 1.4487, time 6.59ms, mfu 0.00%
iter 550: loss 1.4430, time 6.63ms, mfu 0.00%
iter 560: loss 1.4486, time 6.60ms, mfu 0.00%
iter 570: loss 1.4510, time 6.30ms, mfu 0.00%
iter 580: loss 1.4458, time 6.65ms, mfu 0.00%
iter 590: loss 1.4502, time 6.59ms, mfu 0.00%
iter 600: loss 1.4476, time 7.37ms, mfu 0.00%
iter 610: loss 1.4446, time 8.48ms, mfu 0.00%
iter 620: loss 1.4510, time 9.83ms, mfu 0.00%
iter 630: loss 1.4507, time 10.28ms, mfu 0.00%
iter 640: loss 1.4522, time 10.36ms, mfu 0.00%
iter 650: loss 1.4524, time 10.65ms, mfu 0.00%
iter 660: loss 1.4443, time 6.44ms, mfu 0.00%
iter 670: loss 1.4439, time 6.26ms, mfu 0.00%
iter 680: loss 1.4448, time 6.31ms, mfu 0.00%
iter 690: loss 1.4451, time 6.25ms, mfu 0.00%
iter 700: loss 1.4494, time 6.27ms, mfu 0.00%
iter 710: loss 1.4460, time 6.40ms, mfu 0.00%
iter 720: loss 1.4440, time 6.36ms, mfu 0.00%
iter 730: loss 1.4481, time 6.24ms, mfu 0.00%
iter 740: loss 1.4510, time 6.32ms, mfu 0.00%
step 750: train loss 1.4486, val loss 1.4498
saving checkpoint to out-tss50
iter 750: loss 1.4430, time 1125.43ms, mfu 0.00%
iter 760: loss 1.4549, time 6.26ms, mfu 0.00%
iter 770: loss 1.4502, time 6.31ms, mfu 0.00%
iter 780: loss 1.4530, time 6.55ms, mfu 0.00%
iter 790: loss 1.4500, time 7.16ms, mfu 0.00%
iter 800: loss 1.4478, time 8.91ms, mfu 0.00%
iter 810: loss 1.4492, time 8.32ms, mfu 0.00%
iter 820: loss 1.4483, time 9.63ms, mfu 0.00%
iter 830: loss 1.4460, time 9.73ms, mfu 0.00%
iter 840: loss 1.4543, time 9.97ms, mfu 0.00%
iter 850: loss 1.4527, time 9.88ms, mfu 0.00%
iter 860: loss 1.4515, time 6.28ms, mfu 0.00%
iter 870: loss 1.4505, time 6.46ms, mfu 0.00%
iter 880: loss 1.4531, time 6.41ms, mfu 0.00%
iter 890: loss 1.4482, time 6.27ms, mfu 0.00%
iter 900: loss 1.4506, time 6.27ms, mfu 0.00%
iter 910: loss 1.4549, time 6.69ms, mfu 0.00%
iter 920: loss 1.4572, time 6.42ms, mfu 0.00%
iter 930: loss 1.4540, time 6.62ms, mfu 0.00%
iter 940: loss 1.4391, time 6.41ms, mfu 0.00%
iter 950: loss 1.4489, time 6.34ms, mfu 0.00%
iter 960: loss 1.4549, time 7.26ms, mfu 0.00%
iter 970: loss 1.4431, time 8.61ms, mfu 0.00%
iter 980: loss 1.4510, time 10.15ms, mfu 0.00%
iter 990: loss 1.4491, time 14.77ms, mfu 0.00%
step 1000: train loss 1.4486, val loss 1.4493
saving checkpoint to out-tss50
iter 1000: loss 1.4448, time 1018.93ms, mfu 0.00%
iter 1010: loss 1.4421, time 6.45ms, mfu 0.00%
iter 1020: loss 1.4489, time 6.41ms, mfu 0.00%
iter 1030: loss 1.4483, time 6.94ms, mfu 0.00%
iter 1040: loss 1.4508, time 9.10ms, mfu 0.00%
iter 1050: loss 1.4464, time 9.55ms, mfu 0.00%
iter 1060: loss 1.4507, time 9.65ms, mfu 0.00%
iter 1070: loss 1.4390, time 10.09ms, mfu 0.00%
iter 1080: loss 1.4522, time 10.07ms, mfu 0.00%
iter 1090: loss 1.4514, time 6.52ms, mfu 0.00%
iter 1100: loss 1.4417, time 6.35ms, mfu 0.00%
iter 1110: loss 1.4488, time 6.55ms, mfu 0.00%
iter 1120: loss 1.4520, time 6.26ms, mfu 0.00%
iter 1130: loss 1.4473, time 6.25ms, mfu 0.00%
iter 1140: loss 1.4434, time 6.42ms, mfu 0.00%
iter 1150: loss 1.4505, time 6.34ms, mfu 0.00%
iter 1160: loss 1.4562, time 6.53ms, mfu 0.00%
iter 1170: loss 1.4460, time 6.33ms, mfu 0.00%
iter 1180: loss 1.4524, time 6.40ms, mfu 0.00%
iter 1190: loss 1.4529, time 6.28ms, mfu 0.00%
iter 1200: loss 1.4570, time 6.25ms, mfu 0.00%
iter 1210: loss 1.4418, time 6.25ms, mfu 0.00%
iter 1220: loss 1.4447, time 6.33ms, mfu 0.00%
iter 1230: loss 1.4509, time 6.36ms, mfu 0.00%
iter 1240: loss 1.4453, time 6.29ms, mfu 0.00%
step 1250: train loss 1.4490, val loss 1.4487
saving checkpoint to out-tss50
iter 1250: loss 1.4440, time 1129.01ms, mfu 0.00%
iter 1260: loss 1.4508, time 6.52ms, mfu 0.00%
iter 1270: loss 1.4509, time 6.58ms, mfu 0.00%
iter 1280: loss 1.4448, time 6.52ms, mfu 0.00%
iter 1290: loss 1.4440, time 6.57ms, mfu 0.00%
iter 1300: loss 1.4392, time 6.52ms, mfu 0.00%
iter 1310: loss 1.4507, time 6.59ms, mfu 0.00%
iter 1320: loss 1.4593, time 7.05ms, mfu 0.00%
iter 1330: loss 1.4460, time 8.99ms, mfu 0.00%
iter 1340: loss 1.4443, time 9.53ms, mfu 0.00%
iter 1350: loss 1.4488, time 14.03ms, mfu 0.00%
iter 1360: loss 1.4526, time 10.13ms, mfu 0.00%
iter 1370: loss 1.4502, time 9.66ms, mfu 0.00%
iter 1380: loss 1.4440, time 6.37ms, mfu 0.00%
iter 1390: loss 1.4343, time 6.40ms, mfu 0.00%
iter 1400: loss 1.4394, time 6.46ms, mfu 0.00%
iter 1410: loss 1.4489, time 6.33ms, mfu 0.00%
iter 1420: loss 1.4472, time 6.36ms, mfu 0.00%
iter 1430: loss 1.4519, time 6.34ms, mfu 0.00%
iter 1440: loss 1.4495, time 6.34ms, mfu 0.00%
iter 1450: loss 1.4537, time 6.45ms, mfu 0.00%
iter 1460: loss 1.4582, time 6.43ms, mfu 0.00%
iter 1470: loss 1.4415, time 6.37ms, mfu 0.00%
iter 1480: loss 1.4433, time 6.34ms, mfu 0.00%
iter 1490: loss 1.4514, time 6.67ms, mfu 0.00%
step 1500: train loss 1.4488, val loss 1.4490
iter 1500: loss 1.4524, time 1134.29ms, mfu 0.00%
iter 1510: loss 1.4498, time 6.44ms, mfu 0.00%
iter 1520: loss 1.4517, time 6.52ms, mfu 0.00%
iter 1530: loss 1.4515, time 6.27ms, mfu 0.00%
iter 1540: loss 1.4466, time 6.34ms, mfu 0.00%
iter 1550: loss 1.4454, time 6.47ms, mfu 0.00%
iter 1560: loss 1.4393, time 6.27ms, mfu 0.00%
iter 1570: loss 1.4459, time 6.41ms, mfu 0.00%
iter 1580: loss 1.4479, time 6.61ms, mfu 0.00%
iter 1590: loss 1.4594, time 6.65ms, mfu 0.00%
iter 1600: loss 1.4514, time 6.53ms, mfu 0.00%
iter 1610: loss 1.4483, time 6.96ms, mfu 0.00%
iter 1620: loss 1.4449, time 8.97ms, mfu 0.00%
iter 1630: loss 1.4470, time 10.10ms, mfu 0.00%
iter 1640: loss 1.4494, time 10.05ms, mfu 0.00%
iter 1650: loss 1.4569, time 9.91ms, mfu 0.00%
iter 1660: loss 1.4465, time 10.28ms, mfu 0.00%
iter 1670: loss 1.4453, time 6.52ms, mfu 0.00%
iter 1680: loss 1.4513, time 6.67ms, mfu 0.00%
iter 1690: loss 1.4499, time 6.53ms, mfu 0.00%
iter 1700: loss 1.4546, time 6.56ms, mfu 0.00%
iter 1710: loss 1.4450, time 6.63ms, mfu 0.00%
iter 1720: loss 1.4453, time 6.52ms, mfu 0.00%
iter 1730: loss 1.4466, time 6.58ms, mfu 0.00%
iter 1740: loss 1.4530, time 6.63ms, mfu 0.00%
step 1750: train loss 1.4476, val loss 1.4480
saving checkpoint to out-tss50
iter 1750: loss 1.4486, time 1132.19ms, mfu 0.00%
iter 1760: loss 1.4495, time 6.65ms, mfu 0.00%
iter 1770: loss 1.4513, time 6.53ms, mfu 0.00%
iter 1780: loss 1.4497, time 6.54ms, mfu 0.00%
iter 1790: loss 1.4504, time 6.54ms, mfu 0.00%
iter 1800: loss 1.4534, time 6.53ms, mfu 0.00%
iter 1810: loss 1.4503, time 6.24ms, mfu 0.00%
iter 1820: loss 1.4524, time 6.45ms, mfu 0.00%
iter 1830: loss 1.4496, time 6.32ms, mfu 0.00%
iter 1840: loss 1.4413, time 6.30ms, mfu 0.00%
iter 1850: loss 1.4494, time 6.36ms, mfu 0.00%
iter 1860: loss 1.4455, time 6.25ms, mfu 0.00%
iter 1870: loss 1.4508, time 6.26ms, mfu 0.00%
iter 1880: loss 1.4486, time 6.48ms, mfu 0.00%
iter 1890: loss 1.4386, time 7.85ms, mfu 0.00%
iter 1900: loss 1.4491, time 8.47ms, mfu 0.00%
iter 1910: loss 1.4471, time 8.83ms, mfu 0.00%
iter 1920: loss 1.4500, time 10.56ms, mfu 0.00%
iter 1930: loss 1.4538, time 9.67ms, mfu 0.00%
iter 1940: loss 1.4456, time 9.85ms, mfu 0.00%
iter 1950: loss 1.4467, time 6.58ms, mfu 0.00%
iter 1960: loss 1.4505, time 6.34ms, mfu 0.00%
iter 1970: loss 1.4534, time 6.44ms, mfu 0.00%
iter 1980: loss 1.4484, time 6.25ms, mfu 0.00%
iter 1990: loss 1.4476, time 6.49ms, mfu 0.00%
step 2000: train loss 1.4461, val loss 1.4476
saving checkpoint to out-tss50
iter 2000: loss 1.4457, time 965.46ms, mfu 0.00%
iter 2010: loss 1.4478, time 6.58ms, mfu 0.00%
iter 2020: loss 1.4477, time 6.43ms, mfu 0.00%
iter 2030: loss 1.4400, time 6.40ms, mfu 0.00%
iter 2040: loss 1.4519, time 6.51ms, mfu 0.00%
iter 2050: loss 1.4453, time 6.48ms, mfu 0.00%
iter 2060: loss 1.4468, time 6.37ms, mfu 0.00%
iter 2070: loss 1.4433, time 6.36ms, mfu 0.00%
iter 2080: loss 1.4437, time 6.41ms, mfu 0.00%
iter 2090: loss 1.4498, time 6.33ms, mfu 0.00%
iter 2100: loss 1.4494, time 6.29ms, mfu 0.00%
iter 2110: loss 1.4517, time 6.26ms, mfu 0.00%
iter 2120: loss 1.4511, time 6.39ms, mfu 0.00%
iter 2130: loss 1.4526, time 6.44ms, mfu 0.00%
iter 2140: loss 1.4360, time 6.59ms, mfu 0.00%
iter 2150: loss 1.4440, time 6.53ms, mfu 0.00%
iter 2160: loss 1.4488, time 6.29ms, mfu 0.00%
iter 2170: loss 1.4419, time 6.66ms, mfu 0.00%
iter 2180: loss 1.4482, time 6.65ms, mfu 0.00%
iter 2190: loss 1.4416, time 6.76ms, mfu 0.00%
iter 2200: loss 1.4452, time 6.56ms, mfu 0.00%
iter 2210: loss 1.4437, time 7.40ms, mfu 0.00%
iter 2220: loss 1.4534, time 6.52ms, mfu 0.00%
iter 2230: loss 1.4439, time 6.54ms, mfu 0.00%
iter 2240: loss 1.4506, time 6.58ms, mfu 0.00%
step 2250: train loss 1.4458, val loss 1.4464
saving checkpoint to out-tss50
iter 2250: loss 1.4425, time 955.64ms, mfu 0.00%
iter 2260: loss 1.4506, time 6.26ms, mfu 0.00%
iter 2270: loss 1.4506, time 6.27ms, mfu 0.00%
iter 2280: loss 1.4518, time 6.26ms, mfu 0.00%
iter 2290: loss 1.4440, time 6.51ms, mfu 0.00%
iter 2300: loss 1.4390, time 6.50ms, mfu 0.00%
iter 2310: loss 1.4515, time 6.39ms, mfu 0.00%
iter 2320: loss 1.4423, time 6.34ms, mfu 0.00%
iter 2330: loss 1.4414, time 6.27ms, mfu 0.00%
iter 2340: loss 1.4527, time 6.65ms, mfu 0.00%
iter 2350: loss 1.4462, time 6.66ms, mfu 0.00%
iter 2360: loss 1.4563, time 6.53ms, mfu 0.00%
iter 2370: loss 1.4463, time 6.64ms, mfu 0.00%
iter 2380: loss 1.4474, time 6.63ms, mfu 0.00%
iter 2390: loss 1.4452, time 6.53ms, mfu 0.00%
iter 2400: loss 1.4485, time 6.52ms, mfu 0.00%
iter 2410: loss 1.4434, time 6.64ms, mfu 0.00%
iter 2420: loss 1.4484, time 6.55ms, mfu 0.00%
iter 2430: loss 1.4479, time 6.52ms, mfu 0.00%
iter 2440: loss 1.4463, time 6.66ms, mfu 0.00%
iter 2450: loss 1.4472, time 6.62ms, mfu 0.00%
iter 2460: loss 1.4489, time 6.27ms, mfu 0.00%
iter 2470: loss 1.4537, time 6.26ms, mfu 0.00%
iter 2480: loss 1.4417, time 6.27ms, mfu 0.00%
iter 2490: loss 1.4457, time 6.41ms, mfu 0.00%
step 2500: train loss 1.4454, val loss 1.4463
saving checkpoint to out-tss50
iter 2500: loss 1.4418, time 946.54ms, mfu 0.00%
iter 2510: loss 1.4455, time 6.67ms, mfu 0.00%
iter 2520: loss 1.4461, time 6.56ms, mfu 0.00%
iter 2530: loss 1.4463, time 7.09ms, mfu 0.00%
iter 2540: loss 1.4443, time 8.84ms, mfu 0.00%
iter 2550: loss 1.4417, time 9.79ms, mfu 0.00%
iter 2560: loss 1.4574, time 9.58ms, mfu 0.00%
iter 2570: loss 1.4459, time 10.21ms, mfu 0.00%
iter 2580: loss 1.4488, time 10.15ms, mfu 0.00%
iter 2590: loss 1.4533, time 6.59ms, mfu 0.00%
iter 2600: loss 1.4354, time 6.41ms, mfu 0.00%
iter 2610: loss 1.4500, time 6.27ms, mfu 0.00%
iter 2620: loss 1.4371, time 6.56ms, mfu 0.00%
iter 2630: loss 1.4522, time 6.31ms, mfu 0.00%
iter 2640: loss 1.4410, time 6.45ms, mfu 0.00%
iter 2650: loss 1.4514, time 6.24ms, mfu 0.00%
iter 2660: loss 1.4497, time 6.47ms, mfu 0.00%
iter 2670: loss 1.4421, time 6.25ms, mfu 0.00%
iter 2680: loss 1.4379, time 6.32ms, mfu 0.00%
iter 2690: loss 1.4469, time 6.25ms, mfu 0.00%
iter 2700: loss 1.4482, time 6.26ms, mfu 0.00%
iter 2710: loss 1.4468, time 6.43ms, mfu 0.00%
iter 2720: loss 1.4519, time 6.35ms, mfu 0.00%
iter 2730: loss 1.4466, time 6.46ms, mfu 0.00%
iter 2740: loss 1.4429, time 6.56ms, mfu 0.00%
step 2750: train loss 1.4449, val loss 1.4448
saving checkpoint to out-tss50
iter 2750: loss 1.4417, time 1147.56ms, mfu 0.00%
iter 2760: loss 1.4510, time 6.60ms, mfu 0.00%
iter 2770: loss 1.4409, time 6.64ms, mfu 0.00%
iter 2780: loss 1.4461, time 6.45ms, mfu 0.00%
iter 2790: loss 1.4463, time 6.26ms, mfu 0.00%
iter 2800: loss 1.4440, time 6.32ms, mfu 0.00%
iter 2810: loss 1.4501, time 6.64ms, mfu 0.00%
iter 2820: loss 1.4446, time 7.63ms, mfu 0.00%
iter 2830: loss 1.4514, time 9.23ms, mfu 0.00%
iter 2840: loss 1.4438, time 10.26ms, mfu 0.00%
iter 2850: loss 1.4391, time 10.38ms, mfu 0.00%
iter 2860: loss 1.4407, time 9.88ms, mfu 0.00%
iter 2870: loss 1.4469, time 9.98ms, mfu 0.00%
iter 2880: loss 1.4407, time 6.34ms, mfu 0.00%
iter 2890: loss 1.4467, time 6.62ms, mfu 0.00%
iter 2900: loss 1.4590, time 6.44ms, mfu 0.00%
iter 2910: loss 1.4478, time 6.55ms, mfu 0.00%
iter 2920: loss 1.4421, time 6.40ms, mfu 0.00%
iter 2930: loss 1.4533, time 6.35ms, mfu 0.00%
iter 2940: loss 1.4442, time 6.27ms, mfu 0.00%
iter 2950: loss 1.4469, time 6.27ms, mfu 0.00%
iter 2960: loss 1.4455, time 6.48ms, mfu 0.00%
iter 2970: loss 1.4426, time 6.30ms, mfu 0.00%
iter 2980: loss 1.4411, time 6.45ms, mfu 0.00%
iter 2990: loss 1.4417, time 6.47ms, mfu 0.00%
step 3000: train loss 1.4445, val loss 1.4451
iter 3000: loss 1.4447, time 1120.08ms, mfu 0.00%
iter 3010: loss 1.4454, time 6.54ms, mfu 0.00%
iter 3020: loss 1.4457, time 6.49ms, mfu 0.00%
iter 3030: loss 1.4451, time 6.57ms, mfu 0.00%
iter 3040: loss 1.4407, time 6.34ms, mfu 0.00%
iter 3050: loss 1.4372, time 6.37ms, mfu 0.00%
iter 3060: loss 1.4440, time 6.50ms, mfu 0.00%
iter 3070: loss 1.4478, time 6.28ms, mfu 0.00%
iter 3080: loss 1.4456, time 6.36ms, mfu 0.00%
iter 3090: loss 1.4425, time 6.42ms, mfu 0.00%
iter 3100: loss 1.4520, time 6.30ms, mfu 0.00%
iter 3110: loss 1.4392, time 7.06ms, mfu 0.00%
iter 3120: loss 1.4475, time 8.60ms, mfu 0.00%
iter 3130: loss 1.4401, time 9.46ms, mfu 0.00%
iter 3140: loss 1.4340, time 10.18ms, mfu 0.00%
iter 3150: loss 1.4425, time 10.05ms, mfu 0.00%
iter 3160: loss 1.4425, time 9.91ms, mfu 0.00%
iter 3170: loss 1.4448, time 6.55ms, mfu 0.00%
iter 3180: loss 1.4478, time 6.44ms, mfu 0.00%
iter 3190: loss 1.4460, time 6.32ms, mfu 0.00%
iter 3200: loss 1.4475, time 6.40ms, mfu 0.00%
iter 3210: loss 1.4469, time 6.32ms, mfu 0.00%
iter 3220: loss 1.4468, time 6.41ms, mfu 0.00%
iter 3230: loss 1.4468, time 6.39ms, mfu 0.00%
iter 3240: loss 1.4496, time 6.28ms, mfu 0.00%
step 3250: train loss 1.4430, val loss 1.4439
saving checkpoint to out-tss50
iter 3250: loss 1.4491, time 1129.66ms, mfu 0.00%
iter 3260: loss 1.4518, time 6.25ms, mfu 0.00%
iter 3270: loss 1.4405, time 6.54ms, mfu 0.00%
iter 3280: loss 1.4430, time 6.44ms, mfu 0.00%
iter 3290: loss 1.4421, time 6.45ms, mfu 0.00%
iter 3300: loss 1.4486, time 6.25ms, mfu 0.00%
iter 3310: loss 1.4438, time 6.36ms, mfu 0.00%
iter 3320: loss 1.4514, time 6.49ms, mfu 0.00%
iter 3330: loss 1.4386, time 6.43ms, mfu 0.00%
iter 3340: loss 1.4453, time 6.28ms, mfu 0.00%
iter 3350: loss 1.4487, time 6.33ms, mfu 0.00%
iter 3360: loss 1.4418, time 6.33ms, mfu 0.00%
iter 3370: loss 1.4499, time 6.33ms, mfu 0.00%
iter 3380: loss 1.4382, time 6.36ms, mfu 0.00%
iter 3390: loss 1.4326, time 6.42ms, mfu 0.00%
iter 3400: loss 1.4494, time 6.63ms, mfu 0.00%
iter 3410: loss 1.4451, time 8.82ms, mfu 0.00%
iter 3420: loss 1.4470, time 10.18ms, mfu 0.00%
iter 3430: loss 1.4485, time 9.38ms, mfu 0.00%
iter 3440: loss 1.4388, time 10.09ms, mfu 0.00%
iter 3450: loss 1.4358, time 10.17ms, mfu 0.00%
iter 3460: loss 1.4469, time 6.68ms, mfu 0.00%
iter 3470: loss 1.4409, time 6.47ms, mfu 0.00%
iter 3480: loss 1.4506, time 6.54ms, mfu 0.00%
iter 3490: loss 1.4445, time 6.65ms, mfu 0.00%
step 3500: train loss 1.4434, val loss 1.4427
saving checkpoint to out-tss50
iter 3500: loss 1.4435, time 1049.77ms, mfu 0.00%
iter 3510: loss 1.4426, time 9.78ms, mfu 0.00%
iter 3520: loss 1.4456, time 9.92ms, mfu 0.00%
iter 3530: loss 1.4432, time 6.55ms, mfu 0.00%
iter 3540: loss 1.4422, time 6.53ms, mfu 0.00%
iter 3550: loss 1.4508, time 6.33ms, mfu 0.00%
iter 3560: loss 1.4469, time 6.44ms, mfu 0.00%
iter 3570: loss 1.4482, time 6.25ms, mfu 0.00%
iter 3580: loss 1.4460, time 6.43ms, mfu 0.00%
iter 3590: loss 1.4487, time 6.41ms, mfu 0.00%
iter 3600: loss 1.4474, time 6.27ms, mfu 0.00%
iter 3610: loss 1.4460, time 6.25ms, mfu 0.00%
iter 3620: loss 1.4455, time 6.24ms, mfu 0.00%
iter 3630: loss 1.4389, time 6.32ms, mfu 0.00%
iter 3640: loss 1.4402, time 6.35ms, mfu 0.00%
iter 3650: loss 1.4460, time 6.28ms, mfu 0.00%
iter 3660: loss 1.4422, time 6.33ms, mfu 0.00%
iter 3670: loss 1.4468, time 6.57ms, mfu 0.00%
iter 3680: loss 1.4426, time 6.33ms, mfu 0.00%
iter 3690: loss 1.4438, time 6.84ms, mfu 0.00%
iter 3700: loss 1.4435, time 8.88ms, mfu 0.00%
iter 3710: loss 1.4483, time 10.11ms, mfu 0.00%
iter 3720: loss 1.4487, time 10.61ms, mfu 0.00%
iter 3730: loss 1.4444, time 9.82ms, mfu 0.00%
iter 3740: loss 1.4440, time 9.95ms, mfu 0.00%
step 3750: train loss 1.4422, val loss 1.4428
iter 3750: loss 1.4282, time 943.23ms, mfu 0.00%
iter 3760: loss 1.4412, time 6.96ms, mfu 0.00%
iter 3770: loss 1.4408, time 8.98ms, mfu 0.00%
iter 3780: loss 1.4483, time 9.95ms, mfu 0.00%
iter 3790: loss 1.4349, time 10.06ms, mfu 0.00%
iter 3800: loss 1.4322, time 9.71ms, mfu 0.00%
iter 3810: loss 1.4437, time 10.02ms, mfu 0.00%
iter 3820: loss 1.4445, time 6.36ms, mfu 0.00%
iter 3830: loss 1.4429, time 6.36ms, mfu 0.00%
iter 3840: loss 1.4470, time 6.34ms, mfu 0.00%
iter 3850: loss 1.4271, time 6.42ms, mfu 0.00%
iter 3860: loss 1.4465, time 6.42ms, mfu 0.00%
iter 3870: loss 1.4516, time 6.33ms, mfu 0.00%
iter 3880: loss 1.4433, time 6.49ms, mfu 0.00%
iter 3890: loss 1.4461, time 6.41ms, mfu 0.00%
iter 3900: loss 1.4446, time 6.33ms, mfu 0.00%
iter 3910: loss 1.4408, time 6.26ms, mfu 0.00%
iter 3920: loss 1.4444, time 6.32ms, mfu 0.00%
iter 3930: loss 1.4498, time 6.37ms, mfu 0.00%
iter 3940: loss 1.4525, time 6.42ms, mfu 0.00%
iter 3950: loss 1.4439, time 6.35ms, mfu 0.00%
iter 3960: loss 1.4487, time 6.25ms, mfu 0.00%
iter 3970: loss 1.4368, time 6.45ms, mfu 0.00%
iter 3980: loss 1.4529, time 7.05ms, mfu 0.00%
iter 3990: loss 1.4505, time 8.71ms, mfu 0.00%
step 4000: train loss 1.4423, val loss 1.4424
saving checkpoint to out-tss50
iter 4000: loss 1.4461, time 1085.40ms, mfu 0.00%
iter 4010: loss 1.4495, time 6.26ms, mfu 0.00%
iter 4020: loss 1.4535, time 6.43ms, mfu 0.00%
iter 4030: loss 1.4466, time 6.37ms, mfu 0.00%
iter 4040: loss 1.4488, time 6.28ms, mfu 0.00%
iter 4050: loss 1.4523, time 6.70ms, mfu 0.00%
iter 4060: loss 1.4473, time 8.73ms, mfu 0.00%
iter 4070: loss 1.4441, time 9.21ms, mfu 0.00%
iter 4080: loss 1.4413, time 10.44ms, mfu 0.00%
iter 4090: loss 1.4439, time 10.01ms, mfu 0.00%
iter 4100: loss 1.4488, time 10.00ms, mfu 0.00%
iter 4110: loss 1.4437, time 6.53ms, mfu 0.00%
iter 4120: loss 1.4442, time 6.32ms, mfu 0.00%
iter 4130: loss 1.4437, time 6.37ms, mfu 0.00%
iter 4140: loss 1.4419, time 6.26ms, mfu 0.00%
iter 4150: loss 1.4383, time 6.44ms, mfu 0.00%
iter 4160: loss 1.4322, time 6.32ms, mfu 0.00%
iter 4170: loss 1.4456, time 6.33ms, mfu 0.00%
iter 4180: loss 1.4476, time 6.25ms, mfu 0.00%
iter 4190: loss 1.4482, time 6.37ms, mfu 0.00%
iter 4200: loss 1.4430, time 6.67ms, mfu 0.00%
iter 4210: loss 1.4471, time 6.66ms, mfu 0.00%
iter 4220: loss 1.4421, time 6.53ms, mfu 0.00%
iter 4230: loss 1.4426, time 6.60ms, mfu 0.00%
iter 4240: loss 1.4520, time 6.51ms, mfu 0.00%
step 4250: train loss 1.4420, val loss 1.4424
iter 4250: loss 1.4459, time 1131.31ms, mfu 0.00%
iter 4260: loss 1.4397, time 6.55ms, mfu 0.00%
iter 4270: loss 1.4481, time 6.54ms, mfu 0.00%
iter 4280: loss 1.4523, time 6.51ms, mfu 0.00%
iter 4290: loss 1.4404, time 6.62ms, mfu 0.00%
iter 4300: loss 1.4430, time 6.53ms, mfu 0.00%
iter 4310: loss 1.4478, time 6.63ms, mfu 0.00%
iter 4320: loss 1.4490, time 6.33ms, mfu 0.00%
iter 4330: loss 1.4470, time 6.58ms, mfu 0.00%
iter 4340: loss 1.4335, time 7.75ms, mfu 0.00%
iter 4350: loss 1.4449, time 8.99ms, mfu 0.00%
iter 4360: loss 1.4402, time 9.80ms, mfu 0.00%
iter 4370: loss 1.4412, time 9.59ms, mfu 0.00%
iter 4380: loss 1.4451, time 10.94ms, mfu 0.00%
iter 4390: loss 1.4466, time 9.89ms, mfu 0.00%
iter 4400: loss 1.4436, time 6.41ms, mfu 0.00%
iter 4410: loss 1.4448, time 6.24ms, mfu 0.00%
iter 4420: loss 1.4333, time 6.31ms, mfu 0.00%
iter 4430: loss 1.4384, time 6.36ms, mfu 0.00%
iter 4440: loss 1.4448, time 6.41ms, mfu 0.00%
iter 4450: loss 1.4543, time 6.28ms, mfu 0.00%
iter 4460: loss 1.4362, time 6.39ms, mfu 0.00%
iter 4470: loss 1.4453, time 6.25ms, mfu 0.00%
iter 4480: loss 1.4449, time 6.40ms, mfu 0.00%
iter 4490: loss 1.4523, time 6.25ms, mfu 0.00%
step 4500: train loss 1.4417, val loss 1.4423
saving checkpoint to out-tss50
iter 4500: loss 1.4415, time 1130.00ms, mfu 0.00%
iter 4510: loss 1.4447, time 6.34ms, mfu 0.00%
iter 4520: loss 1.4502, time 6.29ms, mfu 0.00%
iter 4530: loss 1.4383, time 6.34ms, mfu 0.00%
iter 4540: loss 1.4351, time 6.45ms, mfu 0.00%
iter 4550: loss 1.4521, time 6.26ms, mfu 0.00%
iter 4560: loss 1.4405, time 6.32ms, mfu 0.00%
iter 4570: loss 1.4355, time 6.44ms, mfu 0.00%
iter 4580: loss 1.4335, time 6.55ms, mfu 0.00%
iter 4590: loss 1.4432, time 6.39ms, mfu 0.00%
iter 4600: loss 1.4505, time 6.61ms, mfu 0.00%
iter 4610: loss 1.4382, time 6.47ms, mfu 0.00%
iter 4620: loss 1.4483, time 6.41ms, mfu 0.00%
iter 4630: loss 1.4381, time 7.08ms, mfu 0.00%
iter 4640: loss 1.4401, time 8.84ms, mfu 0.00%
iter 4650: loss 1.4397, time 9.87ms, mfu 0.00%
iter 4660: loss 1.4476, time 10.82ms, mfu 0.00%
iter 4670: loss 1.4469, time 9.92ms, mfu 0.00%
iter 4680: loss 1.4466, time 10.06ms, mfu 0.00%
iter 4690: loss 1.4432, time 6.35ms, mfu 0.00%
iter 4700: loss 1.4519, time 6.27ms, mfu 0.00%
iter 4710: loss 1.4492, time 6.33ms, mfu 0.00%
iter 4720: loss 1.4391, time 6.30ms, mfu 0.00%
iter 4730: loss 1.4467, time 6.50ms, mfu 0.00%
iter 4740: loss 1.4456, time 6.29ms, mfu 0.00%
step 4750: train loss 1.4419, val loss 1.4421
saving checkpoint to out-tss50
iter 4750: loss 1.4559, time 1106.87ms, mfu 0.00%
iter 4760: loss 1.4398, time 6.69ms, mfu 0.00%
iter 4770: loss 1.4515, time 6.53ms, mfu 0.00%
iter 4780: loss 1.4471, time 6.66ms, mfu 0.00%
iter 4790: loss 1.4436, time 6.63ms, mfu 0.00%
iter 4800: loss 1.4421, time 6.51ms, mfu 0.00%
iter 4810: loss 1.4402, time 6.58ms, mfu 0.00%
iter 4820: loss 1.4482, time 6.67ms, mfu 0.00%
iter 4830: loss 1.4433, time 6.57ms, mfu 0.00%
iter 4840: loss 1.4459, time 6.59ms, mfu 0.00%
iter 4850: loss 1.4455, time 6.25ms, mfu 0.00%
iter 4860: loss 1.4526, time 6.34ms, mfu 0.00%
iter 4870: loss 1.4423, time 6.26ms, mfu 0.00%
iter 4880: loss 1.4453, time 6.26ms, mfu 0.00%
iter 4890: loss 1.4412, time 6.27ms, mfu 0.00%
iter 4900: loss 1.4505, time 6.64ms, mfu 0.00%
iter 4910: loss 1.4438, time 6.94ms, mfu 0.00%
iter 4920: loss 1.4494, time 8.59ms, mfu 0.00%
iter 4930: loss 1.4358, time 8.92ms, mfu 0.00%
iter 4940: loss 1.4550, time 9.57ms, mfu 0.00%
iter 4950: loss 1.4461, time 10.79ms, mfu 0.00%
iter 4960: loss 1.4439, time 9.76ms, mfu 0.00%
iter 4970: loss 1.4454, time 6.31ms, mfu 0.00%
iter 4980: loss 1.4458, time 6.57ms, mfu 0.00%
iter 4990: loss 1.4441, time 6.34ms, mfu 0.00%
step 5000: train loss 1.4419, val loss 1.4427
iter 5000: loss 1.4388, time 992.83ms, mfu 0.00%
2023/08/29 10:49:21 INFO mlflow.projects: === Run (ID 'c3aa706c3d5245a18667a1319133a44c') succeeded ===
